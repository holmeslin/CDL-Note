# 6. Scaling with Google Cloud Operations

## 6.1 Financial Governance and Managing Cloud Costs

### 6.1.1 Fundamentals of cloud financial governance
Easy access to cloud resources presents a need for precise, real-time control of what’s being consumed.
Having cloud financial governance, which is in part a set of processes and controls that organizations use to
manage cloud spend, can mean the difference between peace of mind and spiraling costs that lead to budget overruns.
As an organization adapts, it'll need a core team across technology, finance, and business functions to work together to stay on top of cloud costs and make decisions in real time.
The variable nature of cloud costs impacts people, process, and technology.
Let’s explore these three areas, starting with people.
People refers to the different roles involved in managing cloud costs.
For small organizations, one person might fulfill multiple roles and be responsible for managing all aspects of a cloud infrastructure and associated finance.
From budgeting to procurement, tracking optimization, and more.
Large organizations, however, will likely look to a finance team to take on a financial planning and advisory role.
Using business priorities, a finance team is expected to make data-driven decisions on cloud spending, but
they might struggle to understand or monitor cloud spend on a daily, weekly, or monthly basis.
Then there are members of technology and line of business teams.
They can advise on how cloud resources are being used to meet the organization's overall business strategy and what additional resources might be needed throughout the upcoming year.
However, they don’t necessarily factor costs into their decision making.
To manage cloud costs effectively, a partnership across finance, technology, and business functions is required.
This partnership might already exist, or it may take the form of a centralized hub, such as a cloud center of excellence.
The central team would consist of several experts who ensure that best practices are in place across the organization and that there's visibility into the ongoing cloud spend.
The centralized group would also be able to make real-time decisions and discuss trade-offs when spending is higher than planned.
Now let’s transition from people to process.
On a daily or weekly basis, organizations should monitor and analyze their cloud usage and costs.
Then, on a weekly or monthly basis, the finance team should analyze the results, charge back the costs through the appropriate teams, and determine whether any changes are needed to ensure that the organization's cloud spend is optimized.
Having a culture of accountability in place across teams helps organizations recognize waste, quickly act to eliminate it, and ensure they're maximizing their cloud investment.
It will also help drive cross-group collaboration across technology, finance, and business teams to ensure that their cloud spend aligns with broader business objectives.
And finally, there’s technology.
Google Cloud provides built-in tools to help organizations monitor and manage costs.
These tools help organizations gain greater visibility, drive a culture of accountability for cloud spending across the
organization, control costs to reduce risks of overspending, and provide intelligent recommendations to optimize cost and usage.
You’ll explore some of these tools later in this section.

### 6.1.2 Cloud financial governance best practices

Let’s explore some cloud financial governance best practices that organizations can adopt to increase the predictability and control of their cloud resources.
The first best practice is to identify who manages cloud costs.
If it's a team, it should ideally be a mix of IT managers and financial controllers.
Because Cloud spending is decentralized and variable, it's important to establish a culture of accountability for costs across the organization.
Defining clear ownership for projects and sharing cost views with the departments and teams that are using cloud resources helps establish this accountability culture and more responsible spending.
As well as making teams accountable for their spending, Google Cloud financial governance policies and permissions make it easy to control who can spend and view costs across your organization.
In addition, Google Cloud offers flexible options to organize resources and allocate costs to individual departments and teams.
For example, budgets notify key stakeholders based on your actual or forecasted cloud costs.
Creating multiple budgets with meaningful alerts is an important practice for staying on top of your cloud costs.
The second best practice is to understand what kind of information can be found in an invoice versus cost management tools.
They’re not the same concept.
An invoice is a document that is sent by a cloud service provider to a customer to request payment for the services that were used.
However, a cost management tool is software to help track, analyze, and optimize cloud spend.
An organization is rarely only interested in how much they spend.
They also want to know why they spent that much.
Cost management tools, like those built into the Google Cloud console, are effective for answering the why.
They can provide granular data, uncover trends, and identify actions to take to control or optimize costs.
And this brings us to the third best practice for increasing the predictability and control of cloud resources: use Google Cloud’s cost management tools.
Google Cloud believes in supporting organizations by providing strong financial governance tools that make it easier for customers to align their strategic priorities with their cloud usage.
Before organizations can optimize their cloud costs, they first need to understand what they're spending, whether there are any trends, and what their forecasted costs are.
So, how can this be done?
Start by capturing what cloud resources are being used, by whom, for what purpose, and at what cost.
From there, determine who will be responsible for monitoring that information, who will be involved in managing costs, and how the spending information will be reported on an ongoing basis.
It's also important to set up the cadence and format for ongoing communication with main cloud stakeholders.
Having this plan outlined up front helps ensure that managing costs isn't an afterthought.
And how can you monitor current cost trends and identify areas of waste that could be improved?
Google Cloud provides built-in reporting capabilities, which can help your team gain visibility into costs.
Ideally, reports should be reviewed weekly, at a minimum.
One powerful tool is the Google Cloud Pricing Calculator.
The Pricing Calculator lets you estimate how changes to cloud usage will affect costs.
The calculator is available at cloud.google.com/products/calculator.
Now that you’ve had a chance to explore some cloud financial governance best practices, the next step is to implement them.
If this doesn’t fall into your scope of responsibility, be sure to pass on those best practices to the relevant stakeholders within your organization.

### 6.1.3 Using the resource hierarchy to control access
One important cloud computing consideration involves controlling access to resources.
With on-premises infrastructure, physical access controls were used.
This method, however, is not as effective with resources stored in the cloud.
The Google Cloud resource hierarchy is a powerful tool that can be used to control access to cloud resources.
Much like the folder structure you use to organize and control access to your own files, this resource hierarchy is a tree-like structure that organizes resources into logical groups.
This makes it easier to manage resources and control.
Google Cloud’s resource hierarchy contains four levels, and starting from the bottom up they asources, projects, folders, and an organization node.
The first level, resources, represent virtual machines, Cloud Storage buckets, tables in BigQuery, or anything else in Google Cloud.
Resources are organized into projects, which sit on the second level.
Projects can be organized into folders, or even subfolders.
These sit at the third level.
And then at the top level is an organization node, which encompasses all the projects, folders, and resources in your organization.
It’s important to understand this resource hierarchy because it directly relates to how policies are managed and applied when you use Google Cloud.
A policy is a set of rules that define who can access a resource and what they can do with it.
Policies can be defined at the project, folder, and organization node levels.
Some Google Cloud services can also apply policies to individual resources.
The third level of the Google Cloud resource hierarchy is folders.
Folders let you assign policies to resources at the level of granularity that you choose.
The resources in a folder inherit policies and permissions assigned to that folder.
A folder can contain projects, other folders, or a combination of both.
Now that you understand the structure of the Google Cloud resource hierarchy, let’s explore some additional benefits of using it to control access to cloud resources.
First, the resource hierarchy provides granular access control, meaning you can assign roles and permissions at different levels of the hierarchy, such as at the folder, project, or individual resource level.
Second, because the resource hierarchy follows inheritance and propagation rules, permissions set at higher levels of the resource hierarchy are automatically inherited by lower-level resources.
For example, if you grant a user access at the folder level, all projects and resources within that folder inherit those permissions by default.
This inheritance simplifies access management and reduces the need for manual configuration at each individual resource level.
Third, the resource hierarchy enhances security and compliance through least privilege principles.
By assigning access permissions at the appropriate level in the hierarchy, you can ensure that users only have the necessary privileges to perform their tasks.
This reduces the risk of unauthorized access and helps maintain regulatory compliance.
Finally, the resource hierarchy provides strong visibility and auditing capabilities.
You can track access permissions and changes across different levels of the hierarchy, which makes it easier to monitor and review access controls.
This improves accountability and helps identify and address potential security issues.

### 6.1.4 Controlling cloud consumption

Organizations want to control cloud consumption for many reasons.
It could be about cost savings by ensuring they’re not overspending on unnecessary resources, increased visibility by providing a better understanding of how resources are being used and identifying areas to reduce costs, or improved compliance by ensuring your cloud environment is compliant with industry regulations.
Google Cloud offers several tools to help control cloud consumption, including resource quota policies, budget threshold rules, and Cloud Billing reports.
Let’s define each of these terms.
Resource quota policies let you set limits on the amount of resources that can be used by a project or user.
They can help prevent overspending on cloud resources; therefore, they help you ensure that your cloud usage is within your budget.
Then there are budget threshold rules, which let you set alerts to be informed when your cloud costs exceed a certain threshold.
They can act as an early warning for potential cost overruns, and let you take corrective action before costs get out of control.
Both resource quota policies and budget threshold rules are set in the Google Cloud console.
And then there are Cloud Billing reports.
Whereas resource quota policies and budget threshold rules provide proactive means to control cloud consumption, Cloud Billing reports offer a reactive method to help you track and understand what you’ve already spent on Google Cloud resources and provide ways to help optimize your costs.
You can use Cloud Billing reports to monitor costs by exporting billing data to BigQuery.
This means exporting usage and cost data to a BigQuery dataset, and then using the dataset for detailed analyses.
You can also visualize data with tools like Looker Studio.
After analyzing how you're spending on cloud resources, you might realize that your organization can optimize costs through committed use discounts (CUDs).
If your workloads have predictable resource needs, you can purchase a Google Cloud commitment, which gives you discounted prices in exchange for your commitment to use a minimum level of resources for a specific term.

## 6.2 Operational Excellence and Reliability at Scale

### 6.2.1 Fundamentals of cloud reliability

Within any IT team, developers are responsible for writing code for systems and applications, and operators are responsible for ensuring that those systems and applications operate reliably.
Developers are expected to be agile and are often pushed to write and deploy code quickly.
Their aim is to release new functions frequently, increase core business value with new features, and release fixes fast for an overall better user experience.
In contrast, operators are expected to keep the system stable, and so they often prefer to work more slowly to ensure reliability and consistency.
Traditionally, developers pushed their code to operators who often had little understanding of how the code would run in a production or live environment.
When problems arise, it can be very difficult for either group to identify the source of the problem and resolve it quickly.
Worse, accountability between the teams isn’t always clear.
DevOps is a software development approach that emphasizes collaboration and communication between development and operations teams to enhance the efficiency, speed, and reliability of software delivery.
It aims to break down silos between these teams and foster a culture of shared responsibility, automation, and continuous improvement.
One particular concept within the DevOps framework is Site Reliability Engineering, or SRE, which ensures the reliability, availability, and efficiency of software systems and services deployed in the cloud.
SRE combines aspects of software engineering and operations to design, build, and maintain scalable and reliable infrastructure.
Monitoring is the foundation of product reliability.
It reveals what needs urgent attention and shows trends in application usage patterns, which can yield better capacity planning and generally help improve an application client's experience and lessen their pain.
There are “Four Golden Signals” that measure a system’s performance and reliability.
They are latency, traffic, saturation, and errors.
Latency measures how long it takes for a particular part of a system to return a result.
Latency is important because it directly affects the user experience, changes could indicate emerging issues, its
values might be tied to capacity demands, and it can be used to measure system improvements.
Traffic measures how many requests reach your system.
Traffic is important because it’s an indicator of current system demand, its historical trends are used for capacity planning, and it’s a core measure when calculating infrastructure spend.
Saturation measures how close to capacity a system is.
It’s important to note, though, that capacity is often a subjective measure that depends on the underlying service or application.
Saturation is important because it's an indicator of how full the service is, it focuses on the most constrained resources, and it’s frequently tied to degrading performance as capacity is reached.
And errors are events that measure system failures or other issues.
Errors are often raised when a flaw, failure, or fault in a computer program or system causes it to produce incorrect or unexpected results, or behave in unintended ways.
Errors are important because they can indicate something is failing, configuration or capacity issues, service level objective violations, or that it's time to send an alert.
Three main concepts in site reliability engineering are service-level indicators (SLIs), service-level objectives (SLOs), and service-level agreements (SLAs).
They are all types of targets set for a system’s Four Golden Signal metrics.
Service level indicators are measurements that show how well a system or service is performing.
They’re specific metrics like response time, error rate, or percentage uptime–which is the amount of time a system is available for use–that help us understand the system's behavior and performance.
Service level objectives are the goals that we set for a system's performance based on SLIs.
They define what level of reliability or performance that we want to achieve.
For example, an SLO might state that the system should be available for 99.9% of the time in a month.
Service level agreements are agreements between a cloud service provider and its customers.
They outline the promises and guarantees regarding the quality of service.
SLAs include the agreed-upon SLOs, performance metrics, uptime guarantees, and any penalties or remedies if the provider fails to meet those commitments.
This might include refunds or credits when the service has an outage that’s longer than this agreement allows.

### 6.2.2 Designing resilient infrastructure and processes

When infrastructure and processes in a cloud environment are designed, they need to be resilient, fault-tolerant, and scalable, for high availability and disaster recovery.
High availability refers to the ability of a system to remain operational and accessible for users even if hardware or software failures occur, whereas disaster recovery refers to the process of restoring a system to a functional state after a major disruption or disaster.
Let's explore some of the key design considerations and their significance in more detail.
Redundancy refers to duplicating critical components or resources to provide backup alternatives.
Redundancy can be implemented at various levels, such as hardware, network, or application layers.
For example, having redundant power supplies, network switches, or load balancers ensures that if one fails, the redundant component takes over seamlessly.
Redundancy enhances system reliability and mitigates the impact of single points of failure.
Replication involves creating multiple copies of data or services and distributing them across different servers or locations.
It ensures redundancy and fault tolerance by allowing systems to continue functioning even if certain components or servers fail.
By replicating data across multiple servers, the impact of hardware failures or outages is minimized, and the availability of services is improved.
Cloud service providers offer multiple regions or data center locations spread across different geographic areas.
By distributing resources across regions, businesses can ensure that if an entire region becomes unavailable due to natural disasters, network issues, or other incidents, their services can continue running from another region.
This approach improves resilience and reduces the risk of prolonged service interruptions.
Building a scalable infrastructure allows organizations to handle varying workloads and accommodate increased demand without compromising performance or availability.
Cloud technologies enable the dynamic allocation and deallocation of resources based on workload fluctuations.
Autoscaling mechanisms can automatically adjust resource capacity to match demand, ensuring that services remain available and responsive during peak periods or sudden spikes in traffic.
Regular backups of critical data and configurations are crucial to ensure that if data loss, hardware failures, or cyber-attacks occur, organizations can restore their systems to a previous state.
Cloud providers often offer backup services, and they let organizations automate backups, store them securely, and easily restore data when needed.
Backups should be stored in geographically separate locations to protect against regional outages or disasters.
These measures improve high availability, allow for rapid recovery from disasters or failures, and minimize downtime and data loss.
It’s important to regularly test and validate these processes to ensure that they function as expected during real-world incidents.
Also, monitoring, alerting, and incident response mechanisms should be implemented to identify and address issues promptly, further enhancing the overall resilience and availability of the cloud infrastructure.


### 6.2.3 Modernizing operations by using Google Cloud

If you've ever worked with on-premises environments, you know that you can physically touch the servers.
If an application becomes unresponsive, someone can physically determine why that happened.
In the cloud though, the servers aren't yours—they belong to the cloud provider—and you can’t physically inspect them.
So the question becomes: how do you know what's happening with your server, database, or application?
The answer is: by using Google’s integrated observability tools.
Observability involves collecting, analyzing, and visualizing data from various sources within a system to gain insights into its performance, health, and behavior.
To achieve this, Google Cloud offers Google Cloud Observability, which is a comprehensive set of monitoring, logging, and diagnostics tools.
It offers a unified platform for managing and gaining insights into the performance, availability, and health of applications and infrastructure deployed on Google Cloud.
Let's look at some of the managed services that constitute Google Cloud Observability.
Cloud Monitoring provides a comprehensive view of your cloud infrastructure and applications.
It collects metrics, logs, and traces from your applications and infrastructure, and provides you with insights into their performance, health, and availability.
It also lets you create alerting policies to notify you when metrics, health check results, and uptime check results meet specified criteria.
Cloud Logging collects and stores all application and infrastructure logs.
With real-time insights, you can use Cloud Logging to troubleshoot issues, identify trends, and comply with regulations.
Cloud Trace helps identify performance bottlenecks in applications.
It collects latency data from applications, and provides insights into how they’re performing.
Cloud Profiler identifies how much CPU power, memory, and other resources an application uses.
It continuously gathers CPU usage and memory-allocation information from production applications and provides insights into how applications are using resources.
Error Reporting counts, analyzes, and aggregates the crashes in running cloud services in real-time.
A centralized error management interface displays the results with sorting and filtering capabilities.
A dedicated view shows the error details: time chart, occurrences, affected user count, first- and last-seen dates, and a cleaned exception stack trace.
Error Reporting supports email and mobile alerts notification through its API.
Google's integrated observability tools provided by Google Cloud Observability offer valuable insights into the performance and health of applications and infrastructure in the cloud.

### 6.2.4 Google Cloud Customer Care

Any cloud adoption program can encounter challenges, so it's important to have an effective and efficient support plan from your cloud provider.
Google Cloud Customer Care can simplify and streamline your support experience with scalable and flexible services built with your business needs at the center.
There are four different service levels, which lets you choose the one that’s right for your organization.
Basic Support is free and is included for all Google Cloud customers.
It provides access to documentation, community support, Cloud Billing Support, and Active Assist recommendations.
Active Assist is the portfolio of tools used in Google Cloud to generate insights and recommendations to help you optimize your cloud projects.
Standard Support is recommended for workloads under development.
You can kickstart your cloud journey with unlimited access to tech support, which lets you troubleshoot, test, and explore.
It offers unlimited individual access to English-speaking support representatives during working hours, 5 days a week.
Standard support also provides access to the Cloud Support API, which lets you integrate Cloud Customer Care with your organization's customer relationship management (CRM) system.
Enhanced Support is designed for workloads in production, with fast response times and additional services to optimize your experience with high-quality, robust support.
Support is available 24/7 in a selection of languages, and initial response times are quicker than those provided by Standard Support.
Enhanced Support also offers technical support escalations and third-party technology support to help you resolve multi-vendor issues.
Premium Support is designed for enterprises with critical workloads.
It features the fastest response time, Customer Aware Support, and a dedicated Technical Account Manager.
Our Premium Support level also offers credit for the Google Cloud Skills Boost training platform, an event management service for planned peak events, such as a product launch or major sales events, operational health reviews
to help you measure your progress and proactively address blockers to your goals with Google Cloud, and customer aware support, where Customer Care learns and maintains information about your architecture, partners, and Google Cloud projects.
This information ensures that our support experts can resolve your cases promptly and efficiently.
Both the Enhanced and Premium support plans offer Value-Add Services that are available for additional purchase.
You can learn more about the value-add services and all Google Cloud Customer Care support offerings at cloud.google.com/support.


### 6.2.5 The life of a support case

Any Google Cloud customer on the Standard, Enhanced, or Premium Support plan can use the Google Cloud console to create and manage support cases.
Outside of filing a support case through the Google Cloud console, Customer Care Support also offers other contact options for live interactions with Support staff such as phone and video call support.
The life of a support case during the Google Cloud Customer Care process typically involves several stages and interactions between the customer and the support team.
Here's an overview of the typical journey of a support case.
First, the customer initiates the support request by creating a case in the Google Cloud Console.
Only users who were assigned the Tech Support Editor role within an organization can do this.
The customer provides relevant details about the issue they are experiencing, including any error messages, logs, or steps to reproduce the problem.
It’s important for the user to select a priority from P4, which means low impact, up to P1, which means critical impact, because this will influence response times from the Customer Care team.
After the case is created, it goes through a triage process.
The team reviews the information provided by the customer to understand the problem and determine its severity and impact on the customer's business operations.
The team might request additional information or clarification from the customer at this stage.
In many cases, the Customer Care representative will resolve the case, but for more complex issues, the case is assigned to a support engineer with the appropriate level of expertise.
After the case is assigned, the team starts the troubleshooting and investigation process.
They analyze the provided information, review system logs, and conduct various diagnostic tests to identify the root cause of the issue.
Depending on the complexity of the problem, this stage might involve collaboration with other internal teams or experts.
Throughout the investigation, the Customer Care team maintains regular communication with the customer.
They provide updates on the progress, share findings, and request additional information or actions from the customer when needed.
Escalation is meant for flagging process breaks or for the rare occasion that a case is stuck because a customer and the Customer Care team aren’t fully in sync, despite actively communicating the issue to determine the next steps.
However, it’s important to note that escalation isn’t always the best solution, and with high-impact issues, escalation might not make the case go faster.
This is because escalation can disrupt the workflow of the Customer Care team and lead to delays in other cases.
The best solution for high-impact issues is to ensure that the case is set to the appropriate priority, ensuring that the case is assigned to the right resources as quickly as possible.
Escalation is a tool that can be used to regain traction on a stuck case.
However, it’s important to use escalation sparingly and only when it’s absolutely necessary.
When the root cause is identified, the team works on resolving the issue or providing a mitigation plan.
They might provide the customer with step-by-step instructions, configuration changes, or workaround suggestions to address the problem.
In some cases, they might consult the issue with higher-level support or engineering teams for further assistance.
The Customer Care team might also need to submit a feature request to the Google Cloud engineering team.
After implementing the resolution or mitigation plan, the Customer Care team collaborates with the customer to validate the effectiveness of the solution.
They might request the customer to perform specific tests or provide feedback on the outcome.
This step ensures that the problem is fully resolved and meets the customer's expectations.
When the customer confirms that the issue is resolved, the support case is closed.
The team provides a summary of the resolution, documents the steps taken, and ensures that the customer is satisfied with the outcome.
If needed, they might also offer recommendations for preventive measures or future best practices to avoid similar issues.
The customer also receives a feedback survey, so the support team can learn what they did well and what needs improvement.
Throughout the entire lifecycle of the support case, Google Cloud’s Customer Care team aims to provide timely and effective assistance to the customer.
They prioritize customer satisfaction, responsiveness, and strive to address the possible technical challenges faced by customers when they use Google Cloud services.


## 6.3 Sustainability with Google Cloud

### 6.3.1 Sustainability with Google Cloud

As we get closer to the end of this Cloud Digital Leader training, where you’ve explored how cloud computing can help transform
the way you do business, it’s important that we underscore our technology efforts at Google with our commitment to the environment and sustainability.
The virtual world, which includes Google Cloud’s network, is built on physical infrastructure, and all those racks of humming servers use huge amounts of energy.
Altogether, existing data centers use nearly 2% of the world’s electricity.
With this in mind, Google works to make our data centers run as efficiently as possible.
Just like our customers, Google is trying to look after the planet.
We understand that Google Cloud customers have environmental goals of their own, and running their workloads on Google Cloud can be a part of meeting those goals.
Therefore, it’s useful to note that Google's data centers were the first to achieve ISO 14001 certification, which is a
standard that outlines a framework for an organization to enhance its environmental performance through improving resource efficiency and reducing waste.
As an example of how this is being done, here’s Google’s data center in Hamina, Finland.
This facility is one of the most advanced and efficient data centers in the Google fleet.
Its cooling system, which uses sea water from the Bay of Finland, reduces energy use and is the first of its kind anywhere in the world.
In our founding decade, Google became the first major company to be carbon neutral.
In our second decade, we were the first company to achieve 100% renewable energy.
And by 2030, we aim to be the first major company to operate completely carbon free.
We meet the challenges posed by climate change and the need for resource efficiency by working to
empower everyone—businesses, governments, nonprofit organizations, communities, and individuals—to use Google technology to create a more sustainable world.
So, what does that look like in practice?
Let’s explore an example of how one customer, Kaluza, uses Google Cloud technology to launch
smart electric vehicle charging programs that help customers save money while it reduces their carbon footprint.
Electric vehicles already account for one in seven car sales globally, and with new gas and diesel
cars being phased out across the world, global sales are forecast to reach 73 million units by 2040.
But with power grids becoming increasingly dependent on variable energy sources such as wind and solar, rising
demand from electric vehicles risks overstraining grids at peak times, which can potentially lead to power outages.
Launched by OVO Energy in 2019, Kaluza has taken its deep understanding of the energy market to partner with some of the world’s major energy suppliers and vehicle manufacturers.
With a program called Charge Anytime, customers use Kaluza to smart-charge their electric vehicle, and they pay just about a third of their household electricity rate to do so.
This means that if the customer plugs in their vehicle to charge when they get home from work at, say, 6:00 p.m.—a time when both demand and the carbon intensity on the grid are at their highest—their vehicle will then be smartly charged at the lowest cost and greenest periods throughout the night, which leaves it ready for when they need it in the morning.
Behind Kaluza’s smart charging solution lies some sophisticated technology, all of which is built on Google Cloud.
Their core optimization engine gathers real-time data from a wide range of sources, including battery and charging data from the electric vehicles, and data from the energy suppliers and grid operators, such as the carbon intensity, and price forecasts.
That data is stored in BigQuery where it’s used to train and validate the smart charging optimization models.
These models are then deployed with Google Kubernetes Engine so that whenever a customer plugs in an electric vehicle, data from that vehicle passes in real-time through their optimization engine to calculate the ideal charging schedule for that vehicle, which ensures that it uses the cheapest, least carbon-intensive energy available.
And as for the grid operators and energy companies, the Kaluza platform lets them visualize how many participating electric vehicles are plugged into the network at any one time.
BigQuery and Looker Studio dashboards provide granular insights, such as how many vehicles are idle, how many are charging, and how well our optimization engine is working.
At Google, we remain committed to sustainability and continue to lead and encourage others, like Kaluza, to join us in improving the health of our planet.

## 6.4 Summary

This brings us to the end of the “Scaling with Google Cloud Operations” course.
Let’s do a quick recap.
In the first section of the course titled “Financial governance and managing cloud costs,” you explored the fundamentals of cloud cost management, cloud financial governance best practices, ways to control access by using the resource hierarchy, and ways to control cloud consumption.
In the second section of the course, titled “Operational excellence and reliability at scale,” you learned about modernizing operations by using Google
Cloud, designing resilient infrastructure and processes, the fundamentals of cloud reliability, Google Cloud Customer Care, and the life of a support case.
And finally, in the third section of the course, titled “Sustainability with Google Cloud,” you examined how Google Cloud works to reduce our environmental impact and help organizations meet sustainability goals.
Completing this course also concludes the Cloud Digital Leader learning path.
If you’re looking to demonstrate your knowledge of the topics from these six courses, you’re encouraged to take the Cloud Digital Leader certification exam.
For more information about the exam, including additional resources to help continue your preparation, please visit httloud.google.com/learn/certification/cloud-digital-leader.
And if you’re looking to further expand your knowledge of Google Cloud products and services, please explore the entire catalog at cloud.google.com/training.
